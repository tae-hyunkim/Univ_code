{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1rc0\n"
     ]
    }
   ],
   "source": [
    "import surprise\n",
    "print(surprise.__version__)\n",
    "\n",
    "from surprise import SVD, Reader, Dataset, accuracy, SVDpp ,NMF, KNNBasic, CoClustering, SlopeOne, KNNWithMeans,BaselineOnly, KNNBaseline\n",
    "from surprise.model_selection import  cross_validate, GridSearchCV , train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>time</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-06-25 12:12</td>\n",
       "      <td>에스티로더</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-06-25 12:42</td>\n",
       "      <td>시슬리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-08-26 18:10</td>\n",
       "      <td>크리니크</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-08-26 18:30</td>\n",
       "      <td>듀퐁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-09-03 18:02</td>\n",
       "      <td>랑콤</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid              time   item\n",
       "0    0  2000-06-25 12:12  에스티로더\n",
       "1    0  2000-06-25 12:42    시슬리\n",
       "2    0  2000-08-26 18:10   크리니크\n",
       "3    0  2000-08-26 18:30     듀퐁\n",
       "4    0  2000-09-03 18:02     랑콤"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('transactions.csv',encoding='cp949')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>012베네통</th>\n",
       "      <th>1492</th>\n",
       "      <th>1492마일즈</th>\n",
       "      <th>96NY</th>\n",
       "      <th>A-AND</th>\n",
       "      <th>AB.F.Z</th>\n",
       "      <th>ABFZ</th>\n",
       "      <th>AEG</th>\n",
       "      <th>AQ넥타이</th>\n",
       "      <th>...</th>\n",
       "      <th>후부</th>\n",
       "      <th>후첸로이터</th>\n",
       "      <th>휀시구두</th>\n",
       "      <th>휘나래</th>\n",
       "      <th>휠라슈즈</th>\n",
       "      <th>휠라의류</th>\n",
       "      <th>휠라인티모</th>\n",
       "      <th>휠라키즈</th>\n",
       "      <th>휴고보스</th>\n",
       "      <th>흙침대</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1339 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid  012베네통  1492  1492마일즈  96NY  A-AND  AB.F.Z  ABFZ  AEG  AQ넥타이 ...   후부  \\\n",
       "0    0       0     0        0     0      0       0     0    0      0 ...    0   \n",
       "1    1       0     0        0     0      0       0     0    0      0 ...    0   \n",
       "2    2       0     0        0     0      0       0     0    0      0 ...    0   \n",
       "3    3       0     0        0     0      0       0     0    0      0 ...    0   \n",
       "4    4       0     0        0     0      0       0     0    0      0 ...    0   \n",
       "\n",
       "   후첸로이터  휀시구두  휘나래  휠라슈즈  휠라의류  휠라인티모  휠라키즈  휴고보스  흙침대  \n",
       "0      0     0    0     0     0      0     0     0    0  \n",
       "1      0     0    0     0     0      0     0     0    0  \n",
       "2      0     0    0     0     0      0     0     0    0  \n",
       "3      0     0    0     1     0      1     0     0    0  \n",
       "4      0     0    0     0     0      0     0     0    0  \n",
       "\n",
       "[5 rows x 1339 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rating값을 만들기 위한 Pivot 작업 \n",
    "a = ratings.pivot_table(index='uid',columns='item',values='time',aggfunc=np.size,fill_value=0).reset_index()\n",
    "a.columns.name = None;a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot한 DF를 Long Form 형태의 데이터로 변환 -> uid, item, rating에 대한 정보를 가지도록 \n",
    "ratings = pd.melt(a,id_vars='uid',value_name='rating',var_name='item')\n",
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   6,   4,   3,   2,   5,   8,  14,   7,  15,  11,  12,\n",
       "        10,  20,   9,  16,  34,  13,  19,  21,  17,  40,  55,  50,  33,\n",
       "        30,  36,  18,  79,  39,  99,  37,  48,  27,  22,  45, 147,  54,\n",
       "        64,  24,  29,  23,  41,  53,  31, 101, 207,  47, 111,  25,  35,\n",
       "        38,  46,  43,  71,  32,  80,  57,  28, 138,  83,  49,  61,  52,\n",
       "        42,  70,  86,  59], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rating 값을 0과 1의 Sclae 가지도록 변환 -> 구매여부 데이터로 만듦.\n",
    "ratings.rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>012베네통</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>012베네통</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>012베네통</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid    item  rating\n",
       "0    0  012베네통       0\n",
       "1    1  012베네통       0\n",
       "2    2  012베네통       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>012베네통</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>012베네통</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>012베네통</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>012베네통</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>012베네통</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid    item  rating\n",
       "0    0  012베네통       1\n",
       "1    1  012베네통       1\n",
       "2    2  012베네통       1\n",
       "3    3  012베네통       1\n",
       "4    4  012베네통       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ratings = ratings.sort_values('uid')\n",
    "# ratings.index = range(len(ratings))\n",
    "ratings['rating'] = ratings['rating'].map(lambda x : 0 if x == 0 else 1  ) + 1\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surprise에 삽입하기 전 Surprise에서 원하는 형태로 데이터를 지정 \n",
    "# 이때 scale이 1,2인 이유는 NMF를 실행할 떄 ZeroDivision 문제가 발생해 이를 없애기 위해 rating에 +1을 해주었음 \n",
    "reader = Reader(rating_scale = (1,2))\n",
    "data_set = Dataset.load_from_df(ratings[['uid','item','rating']],reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 앞으로 해야할일 \n",
    "\n",
    "* model tunning. \n",
    "\n",
    "* cross validate 성능. \n",
    "\n",
    "* precision, recall 값 확인하기. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD, Reader, Dataset, accuracy, SVDpp ,NMF, KNNBasic, KNNBaseline, CoClustering, SlopeOne, KNNWithMeans, KNNWithZScore\n",
    "model = [SVD ,SVDpp ,NMF ,KNNBasic ,\n",
    "        KNNBaseline , KNNWithMeans,\n",
    "        CoClustering , SlopeOne, BaselineOnly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svd =  {'n_epochs': [20, 40], 'n_factors': [50, 100], 'lr_all':[0.001,0.01,0.1],'random_state':[0] }\n",
    "grid_svdpp =  {'n_epochs': [20,40], 'n_factors': [50,100],'random_state':[0] }\n",
    "grid_nmf =  {'n_epochs': [20, 40, 50], 'n_factors': [15, 30],'random_state':[0]}\n",
    "grid_basic = {'k':[20,40,60],'min_k':[1,3],'random_state':[0]}\n",
    "grid_base =  {'k':[20,40,60],'min_k':[1,3],'random_state':[0]}\n",
    "grid_means =  {'k':[20,40,60],'min_k':[1,3],'random_state':[0]}\n",
    "grid_Co = {'n_cltr_u':[2,3,5],'n_cltr_i':[2,3,5],'n_epochs':[10,20],'random_state':[0]}\n",
    "# grid_slop = slope는 모르겠다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1087806182792397\n",
      "{'n_epochs': 20, 'n_factors': 100, 'lr_all': 0.01, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "grid_svd_t = GridSearchCV(model[0], grid_svd, measures=['rmse', 'mae'], cv=3)\n",
    "grid_svd_t.fit(data_set)\n",
    "print(grid_svd_t.best_score['rmse'])\n",
    "print(grid_svd_t.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도저히 돌릴 엄두가 나지 않습니다. 교수님... \n",
    "grid_svdpp_t = GridSearchCV(model[1], grid_svdpp, measures=['rmse', 'mae'], cv=3)\n",
    "grid_svdpp_t.fit(data_set)\n",
    "print(grid_svdpp_t.best_score['rmse'])\n",
    "print(grid_svdpp_t.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10933546181627735\n",
      "{'n_epochs': 20, 'n_factors': 15, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "grid_nmf_t = GridSearchCV(model[2], grid_nmf, measures=['rmse', 'mae'], cv=3)\n",
    "grid_nmf_t.fit(data_set)\n",
    "print(grid_nmf_t.best_score['rmse'])\n",
    "print(grid_nmf_t.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.11010377826777369\n",
      "{'k': 60, 'min_k': 1, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "grid_basic_t = GridSearchCV(model[3], grid_basic, measures=['rmse', 'mae'], cv=3)\n",
    "grid_basic_t.fit(data_set)\n",
    "print(grid_basic_t.best_score['rmse'])\n",
    "print(grid_basic_t.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.10938508019285713\n",
      "{'k': 60, 'min_k': 1, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "grid_base_t = GridSearchCV(model[4], grid_base, measures=['rmse', 'mae'], cv=3)\n",
    "grid_base_t.fit(data_set)\n",
    "print(grid_base_t.best_score['rmse'])\n",
    "print(grid_base_t.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.10940397697871025\n",
      "{'k': 60, 'min_k': 1, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "grid_means_t = GridSearchCV(model[5], grid_means, measures=['rmse', 'mae'], cv=3)\n",
    "grid_means_t.fit(data_set)\n",
    "print(grid_means_t.best_score['rmse'])\n",
    "print(grid_means_t.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10808746236751765\n",
      "{'n_cltr_u': 5, 'n_cltr_i': 2, 'n_epochs': 20, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "grid_Co_t = GridSearchCV(model[6], grid_Co, measures=['rmse', 'mae'], cv=3)\n",
    "grid_Co_t.fit(data_set)\n",
    "print(grid_Co_t.best_score['rmse'])\n",
    "print(grid_Co_t.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 튜닝 후 모델 Crossvalid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.1083  0.1094  0.1076  0.1098  0.1088  0.1088  0.0008  \n",
      "MAE (testset)     0.0255  0.0259  0.0255  0.0260  0.0261  0.0258  0.0003  \n",
      "Fit time          70.10   70.22   68.88   68.68   70.03   69.58   0.66    \n",
      "Test time         3.80    3.74    3.83    3.93    3.91    3.84    0.07    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.10831665, 0.10944864, 0.10756789, 0.10979617, 0.10880702]),\n",
       " 'test_mae': array([0.02551811, 0.0259116 , 0.02547544, 0.02596267, 0.0261012 ]),\n",
       " 'fit_time': (70.0985517501831,\n",
       "  70.21830606460571,\n",
       "  68.87685441970825,\n",
       "  68.68437004089355,\n",
       "  70.02674555778503),\n",
       " 'test_time': (3.801835775375366,\n",
       "  3.742994546890259,\n",
       "  3.8277621269226074,\n",
       "  3.9294962882995605,\n",
       "  3.9055960178375244)}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svd_tune = SVD(n_epochs =  20, n_factors =  100, lr_all=  0.01, random_state =  0)\n",
    "cross_validate(model_svd_tune, data_set, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVDpp on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.1077  0.1099  0.1082  0.1083  0.1090  0.1086  0.0008  \n",
      "MAE (testset)     0.0253  0.0259  0.0255  0.0255  0.0257  0.0256  0.0002  \n",
      "Fit time          17824.0319372.0419505.5417497.1618666.4418573.04804.39  \n",
      "Test time         392.77  382.46  308.60  324.59  523.92  386.47  75.95   \n",
      "94809.20407176018\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "startTime = time.time()\n",
    "\n",
    "svdpp = SVDpp(random_state=0)\n",
    "cross_validate(svdpp, data_set, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "endTime = time.time() - startTime\n",
    "print(endTime)\n",
    "# cross valid 94800초... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm NMF on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.1104  0.1094  0.1078  0.1094  0.1097  0.1094  0.0008  \n",
      "MAE (testset)     0.0301  0.0301  0.0298  0.0300  0.0301  0.0300  0.0001  \n",
      "Fit time          30.22   30.71   31.15   30.86   30.46   30.68   0.32    \n",
      "Test time         3.66    3.82    3.70    3.60    3.59    3.67    0.08    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.11038397, 0.10943183, 0.10782085, 0.10943391, 0.10973727]),\n",
       " 'test_mae': array([0.03013064, 0.03008718, 0.02981502, 0.03000056, 0.03006831]),\n",
       " 'fit_time': (30.22419309616089,\n",
       "  30.713884830474854,\n",
       "  31.154707193374634,\n",
       "  30.86149263381958,\n",
       "  30.456576108932495),\n",
       " 'test_time': (3.6611969470977783,\n",
       "  3.8227267265319824,\n",
       "  3.695162296295166,\n",
       "  3.599336624145508,\n",
       "  3.5883681774139404)}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nmf_tune = NMF(n_epochs= 20, n_factors= 15, random_state= 0)\n",
    "cross_validate(model_nmf_tune, data_set, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.1099  0.1100  0.1096  0.1112  0.1110  0.1103  0.0006  \n",
      "MAE (testset)     0.0154  0.0153  0.0151  0.0155  0.0155  0.0154  0.0001  \n",
      "Fit time          24.64   24.36   24.76   24.32   24.29   24.48   0.19    \n",
      "Test time         186.71  160.07  169.06  184.87  180.69  176.28  10.17   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.10990461, 0.1099856 , 0.10959249, 0.111163  , 0.11095615]),\n",
       " 'test_mae': array([0.01536798, 0.01528523, 0.01511461, 0.01551994, 0.01549038]),\n",
       " 'fit_time': (24.64302110671997,\n",
       "  24.36378240585327,\n",
       "  24.760759353637695,\n",
       "  24.32093572616577,\n",
       "  24.289018869400024),\n",
       " 'test_time': (186.71180486679077,\n",
       "  160.06844425201416,\n",
       "  169.0589861869812,\n",
       "  184.86823081970215,\n",
       "  180.6891574859619)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_basic_tune = KNNBasic(k = 60, min_k = 1, random_state = 0)\n",
    "cross_validate(model_basic_tune, data_set, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.1107  0.1090  0.1086  0.1100  0.1095  0.1095  0.0007  \n",
      "MAE (testset)     0.0254  0.0251  0.0250  0.0252  0.0251  0.0252  0.0001  \n",
      "Fit time          27.84   27.85   28.07   28.04   28.04   27.97   0.10    \n",
      "Test time         190.53  204.99  200.18  179.70  176.68  190.42  11.06   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.11067051, 0.10902083, 0.10858495, 0.10996179, 0.10949841]),\n",
       " 'test_mae': array([0.02535736, 0.02509733, 0.02504003, 0.0251994 , 0.02507364]),\n",
       " 'fit_time': (27.843512773513794,\n",
       "  27.848638772964478,\n",
       "  28.07289719581604,\n",
       "  28.043243646621704,\n",
       "  28.040338277816772),\n",
       " 'test_time': (190.52637696266174,\n",
       "  204.99256348609924,\n",
       "  200.18286442756653,\n",
       "  179.70141506195068,\n",
       "  176.6778793334961)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_base_tune = KNNBaseline(k = 60, min_k = 1, random_state = 0)\n",
    "cross_validate(model_base_tune, data_set, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.1096  0.1081  0.1093  0.1095  0.1112  0.1096  0.0010  \n",
      "MAE (testset)     0.0254  0.0251  0.0254  0.0253  0.0256  0.0254  0.0002  \n",
      "Fit time          24.39   24.65   24.85   24.69   24.71   24.66   0.15    \n",
      "Test time         164.86  178.27  181.65  173.18  173.04  174.20  5.69    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.10961098, 0.10811974, 0.10934424, 0.10953268, 0.11119409]),\n",
       " 'test_mae': array([0.02537351, 0.02513203, 0.02537687, 0.02531126, 0.02564145]),\n",
       " 'fit_time': (24.391693115234375,\n",
       "  24.648043155670166,\n",
       "  24.854537963867188,\n",
       "  24.690675497055054,\n",
       "  24.709857940673828),\n",
       " 'test_time': (164.86295175552368,\n",
       "  178.2682011127472,\n",
       "  181.65304851531982,\n",
       "  173.18196773529053,\n",
       "  173.03623175621033)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mean_tune = KNNWithMeans(k = 60, min_k = 1, random_state = 0)\n",
    "cross_validate(model_mean_tune, data_set, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm CoClustering on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.1083  0.1084  0.1082  0.1075  0.1076  0.1080  0.0004  \n",
      "MAE (testset)     0.0243  0.0244  0.0243  0.0241  0.0241  0.0242  0.0001  \n",
      "Fit time          30.46   30.79   30.94   30.93   31.08   30.84   0.21    \n",
      "Test time         2.22    2.22    2.76    1.71    2.76    2.33    0.40    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.10833752, 0.10840562, 0.10817118, 0.10754992, 0.10762276]),\n",
       " 'test_mae': array([0.02427153, 0.02436943, 0.02425058, 0.02406766, 0.02411071]),\n",
       " 'fit_time': (30.459043979644775,\n",
       "  30.79062795639038,\n",
       "  30.939228534698486,\n",
       "  30.925268173217773,\n",
       "  31.077919960021973),\n",
       " 'test_time': (2.2210581302642822,\n",
       "  2.215073585510254,\n",
       "  2.7576825618743896,\n",
       "  1.7084832191467285,\n",
       "  2.762547492980957)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Co_tune = CoClustering(n_cltr_u= 5, n_cltr_i= 2, n_epochs= 20, random_state= 0)\n",
    "cross_validate(model_Co_tune, data_set, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SlopeOne on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.1076  0.1090  0.1087  0.1083  0.1085  0.1084  0.0005  \n",
      "MAE (testset)     0.0248  0.0251  0.0250  0.0250  0.0250  0.0250  0.0001  \n",
      "Fit time          86.52   94.48   94.66   92.91   94.86   92.69   3.16    \n",
      "Test time         225.48  221.99  227.58  225.65  209.70  222.08  6.45    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.10760215, 0.1089728 , 0.10868311, 0.10831098, 0.10847233]),\n",
       " 'test_mae': array([0.02482256, 0.02513277, 0.02498213, 0.02495352, 0.02502482]),\n",
       " 'fit_time': (86.5235288143158,\n",
       "  94.47721338272095,\n",
       "  94.66081190109253,\n",
       "  92.91421818733215,\n",
       "  94.86434388160706),\n",
       " 'test_time': (225.47584867477417,\n",
       "  221.98713207244873,\n",
       "  227.58317732810974,\n",
       "  225.64933252334595,\n",
       "  209.70272541046143)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_slope = SlopeOne()\n",
    "cross_validate(model_slope, data_set, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.1087  0.1078  0.1094  0.1089  0.1071  0.1084  0.0008  \n",
      "MAE (testset)     0.0250  0.0247  0.0251  0.0251  0.0248  0.0249  0.0002  \n",
      "Fit time          3.65    4.03    4.06    4.04    4.05    3.97    0.16    \n",
      "Test time         3.01    1.66    3.07    1.78    3.00    2.50    0.64    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.10869986, 0.10784098, 0.10940705, 0.10893857, 0.10714275]),\n",
       " 'test_mae': array([0.02499209, 0.02467891, 0.02511214, 0.02509441, 0.02479735]),\n",
       " 'fit_time': (3.654224157333374,\n",
       "  4.0292582511901855,\n",
       "  4.059196710586548,\n",
       "  4.036203384399414,\n",
       "  4.049168348312378),\n",
       " 'test_time': (3.005958080291748,\n",
       "  1.6585779190063477,\n",
       "  3.0707285404205322,\n",
       "  1.7782411575317383,\n",
       "  2.9950437545776367)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_base = BaselineOnly()\n",
    "cross_validate(model_base, data_set, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recall and pricision score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    '''Return precision and recall at k metrics for each user.'''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 precisions: 0.924\n",
      "iter 1 recalls: 0.20196911976911971\n",
      "iter 2 precisions: 0.931\n",
      "iter 2 recalls: 0.2056928926465692\n",
      "iter 3 precisions: 0.932\n",
      "iter 3 recalls: 0.20524818139376963\n",
      "iter 4 precisions: 0.946\n",
      "iter 4 recalls: 0.17738269508269497\n",
      "iter 5 precisions: 0.917\n",
      "iter 5 recalls: 0.18542189697557332\n",
      "Mean Precision Score is  0.9299999999999999\n",
      "std Precision Score is  0.009654014708917708\n",
      "Mean recall Score is  0.19514295717354538\n",
      "std recall Score is  0.011575310896174548\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5,random_state=0)\n",
    "model_svd_tune = SVD(n_epochs =  20, n_factors =  100, lr_all=  0.01, random_state =  0)\n",
    "precision_svd = []\n",
    "recall_svd = []\n",
    "i = 1\n",
    "for trainset, testset in kf.split(data_set):\n",
    "    model_svd_tune.fit(trainset)\n",
    "    predictions = model_svd_tune.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=1.5)\n",
    "    p = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    r = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    \n",
    "    precision_svd.append(p)\n",
    "    recall_svd.append(r)\n",
    "    \n",
    "    # Precision and recall can then be averaged over all users\n",
    "    print('iter {} precisions:'.format(i),p)\n",
    "    print('iter {} recalls:'.format(i),r)\n",
    "    i += 1\n",
    "print('Mean Precision Score is ', np.mean(precision_svd))\n",
    "print('std Precision Score is ', np.std(precision_svd))\n",
    "print('Mean recall Score is ', np.mean(recall_svd))\n",
    "print('std recall Score is ', np.std(recall_svd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 precisions: 0.931\n",
      "iter 1 recalls: 0.20316656763715582\n",
      "iter 2 precisions: 0.929\n",
      "iter 2 recalls: 0.18425639262698093\n",
      "iter 3 precisions: 0.93\n",
      "iter 3 recalls: 0.19362829392829398\n",
      "iter 4 precisions: 0.92\n",
      "iter 4 recalls: 0.19555034214151853\n",
      "iter 5 precisions: 0.94\n",
      "iter 5 recalls: 0.18752153622521273\n",
      "Mean Precision Score is  0.93\n",
      "std Precision Score is  0.006356099432828252\n",
      "Mean recall Score is  0.1928246265118324\n",
      "std recall Score is  0.006581315244590704\n"
     ]
    }
   ],
   "source": [
    "# NMF\n",
    "kf = KFold(n_splits=5,random_state=0)\n",
    "model_nmf_tune =NMF(n_epochs= 20, n_factors= 15, random_state= 0)\n",
    "precision_nmf = []\n",
    "recall_nmf = []\n",
    "i = 1\n",
    "for trainset, testset in kf.split(data_set):\n",
    "    model_nmf_tune.fit(trainset)\n",
    "    predictions = model_nmf_tune.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=1.5)\n",
    "    p = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    r = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    \n",
    "    precision_nmf.append(p)\n",
    "    recall_nmf.append(r)\n",
    "    \n",
    "    # Precision and recall can then be averaged over all users\n",
    "    print('iter {} precisions:'.format(i),p)\n",
    "    print('iter {} recalls:'.format(i),r)\n",
    "    i += 1\n",
    "print('Mean Precision Score is ', np.mean(precision_nmf))\n",
    "print('std Precision Score is ', np.std(precision_nmf))\n",
    "print('Mean recall Score is ', np.mean(recall_nmf))\n",
    "print('std recall Score is ', np.std(recall_nmf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "iter 1 precisions: 1.0\n",
      "iter 1 recalls: 0.167\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "iter 2 precisions: 1.0\n",
      "iter 2 recalls: 0.152\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "iter 3 precisions: 1.0\n",
      "iter 3 recalls: 0.142\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "iter 4 precisions: 1.0\n",
      "iter 4 recalls: 0.15220238095238095\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "iter 5 precisions: 1.0\n",
      "iter 5 recalls: 0.15\n",
      "Mean Precision Score is  1.0\n",
      "std Precision Score is  0.0\n",
      "Mean recall Score is  0.1526404761904762\n",
      "std recall Score is  0.00808690187027211\n"
     ]
    }
   ],
   "source": [
    "# KNNbasic\n",
    "kf = KFold(n_splits=5,random_state=0)\n",
    "model_knnbasic_tune =KNNBasic(k = 60, min_k = 1, random_state = 0)\n",
    "precision_knnbasic = []\n",
    "recall_knnbasic = []\n",
    "i = 1\n",
    "for trainset, testset in kf.split(data_set):\n",
    "    model_knnbasic_tune.fit(trainset)\n",
    "    predictions = model_knnbasic_tune.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=1.5)\n",
    "    p = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    r = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    \n",
    "    precision_knnbasic.append(p)\n",
    "    recall_knnbasic.append(r)\n",
    "    \n",
    "    # Precision and recall can then be averaged over all users\n",
    "    print('iter {} precisions:'.format(i),p)\n",
    "    print('iter {} recalls:'.format(i),r)\n",
    "    i += 1\n",
    "print('Mean Precision Score is ', np.mean(precision_knnbasic))\n",
    "print('std Precision Score is ', np.std(precision_knnbasic))\n",
    "print('Mean recall Score is ', np.mean(recall_knnbasic))\n",
    "print('std recall Score is ', np.std(recall_knnbasic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "iter 1 precisions: 1.0\n",
      "iter 1 recalls: 0.15314583333333331\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "iter 2 precisions: 1.0\n",
      "iter 2 recalls: 0.165\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "iter 3 precisions: 1.0\n",
      "iter 3 recalls: 0.1410769230769231\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "iter 4 precisions: 1.0\n",
      "iter 4 recalls: 0.16817424242424242\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "iter 5 precisions: 1.0\n",
      "iter 5 recalls: 0.16543611111111114\n",
      "Mean Precision Score is  1.0\n",
      "std Precision Score is  0.0\n",
      "Mean recall Score is  0.158566621989122\n",
      "std recall Score is  0.010160306309786316\n"
     ]
    }
   ],
   "source": [
    "# KNNBaseline\n",
    "kf = KFold(n_splits=5,random_state=0)\n",
    "model_KNNBaseline_tune =KNNBaseline(k = 60, min_k = 1, random_state = 0)\n",
    "precision_KNNBaseline = []\n",
    "recall_KNNBaseline = []\n",
    "i = 1\n",
    "for trainset, testset in kf.split(data_set):\n",
    "    model_KNNBaseline_tune.fit(trainset)\n",
    "    predictions = model_KNNBaseline_tune.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=1.5)\n",
    "    p = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    r = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    \n",
    "    precision_KNNBaseline.append(p)\n",
    "    recall_KNNBaseline.append(r)\n",
    "    \n",
    "    # Precision and recall can then be averaged over all users\n",
    "    print('iter {} precisions:'.format(i),p)\n",
    "    print('iter {} recalls:'.format(i),r)\n",
    "    i += 1\n",
    "print('Mean Precision Score is ', np.mean(precision_KNNBaseline))\n",
    "print('std Precision Score is ', np.std(precision_KNNBaseline))\n",
    "print('Mean recall Score is ', np.mean(recall_KNNBaseline))\n",
    "print('std recall Score is ', np.std(recall_KNNBaseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "iter 1 precisions: 1.0\n",
      "iter 1 recalls: 0.1593921568627451\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "iter 2 precisions: 1.0\n",
      "iter 2 recalls: 0.159\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "iter 3 precisions: 1.0\n",
      "iter 3 recalls: 0.1511969696969697\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "iter 4 precisions: 1.0\n",
      "iter 4 recalls: 0.14918382352941176\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "iter 5 precisions: 1.0\n",
      "iter 5 recalls: 0.16455882352941176\n",
      "Mean Precision Score is  1.0\n",
      "std Precision Score is  0.0\n",
      "Mean recall Score is  0.15666635472370766\n",
      "std recall Score is  0.00567572739074159\n"
     ]
    }
   ],
   "source": [
    "# KNNWithmeanscore\n",
    "kf = KFold(n_splits=5,random_state=0)\n",
    "model_KNNMEAN_tune =KNNWithMeans(k = 60, min_k = 1, random_state = 0)\n",
    "precision_KNNMEAN = []\n",
    "recall_KNNMEAN = []\n",
    "i = 1\n",
    "for trainset, testset in kf.split(data_set):\n",
    "    model_KNNMEAN_tune.fit(trainset)\n",
    "    predictions = model_KNNMEAN_tune.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=1.5)\n",
    "    p = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    r = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    \n",
    "    precision_KNNMEAN.append(p)\n",
    "    recall_KNNMEAN.append(r)\n",
    "    \n",
    "    # Precision and recall can then be averaged over all users\n",
    "    print('iter {} precisions:'.format(i),p)\n",
    "    print('iter {} recalls:'.format(i),r)\n",
    "    i += 1\n",
    "print('Mean Precision Score is ', np.mean(precision_KNNMEAN))\n",
    "print('std Precision Score is ', np.std(precision_KNNMEAN))\n",
    "print('Mean recall Score is ', np.mean(recall_KNNMEAN))\n",
    "print('std recall Score is ', np.std(recall_KNNMEAN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 precisions: 0.93\n",
      "iter 1 recalls: 0.1986975441225441\n",
      "iter 2 precisions: 0.912\n",
      "iter 2 recalls: 0.2242332763712559\n",
      "iter 3 precisions: 0.939\n",
      "iter 3 recalls: 0.19411113875804273\n",
      "iter 4 precisions: 0.938\n",
      "iter 4 recalls: 0.17801841304120708\n",
      "iter 5 precisions: 0.931\n",
      "iter 5 recalls: 0.2001919164169164\n",
      "Mean Precision Score is  0.93\n",
      "std Precision Score is  0.009695359714832628\n",
      "Mean recall Score is  0.19905045774199323\n",
      "std recall Score is  0.01484820262769046\n"
     ]
    }
   ],
   "source": [
    "# Coclustering\n",
    "kf = KFold(n_splits=5,random_state=0)\n",
    "model_Coclustering_tune = CoClustering(n_cltr_u= 5, n_cltr_i= 2, n_epochs= 20, random_state= 0)\n",
    "precision_Coclustering = []\n",
    "recall_Coclustering = []\n",
    "i = 1\n",
    "for trainset, testset in kf.split(data_set):\n",
    "    model_Coclustering_tune.fit(trainset)\n",
    "    predictions = model_Coclustering_tune.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=1.5)\n",
    "    p = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    r = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    \n",
    "    precision_Coclustering.append(p)\n",
    "    recall_Coclustering.append(r)\n",
    "    \n",
    "    # Precision and recall can then be averaged over all users\n",
    "    print('iter {} precisions:'.format(i),p)\n",
    "    print('iter {} recalls:'.format(i),r)\n",
    "    i += 1\n",
    "print('Mean Precision Score is ', np.mean(precision_Coclustering))\n",
    "print('std Precision Score is ', np.std(precision_Coclustering))\n",
    "print('Mean recall Score is ', np.mean(recall_Coclustering))\n",
    "print('std recall Score is ', np.std(recall_Coclustering))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 precisions: 0.921\n",
      "iter 1 recalls: 0.18974592896783288\n",
      "iter 2 precisions: 0.941\n",
      "iter 2 recalls: 0.19075420592479408\n",
      "iter 3 precisions: 0.926\n",
      "iter 3 recalls: 0.21312556650865463\n",
      "iter 4 precisions: 0.934\n",
      "iter 4 recalls: 0.19245734217473348\n",
      "iter 5 precisions: 0.928\n",
      "iter 5 recalls: 0.19958594183594183\n",
      "Mean Precision Score is  0.93\n",
      "std Precision Score is  0.006899275324264107\n",
      "Mean recall Score is  0.19713379708239137\n",
      "std recall Score is  0.008705156085845843\n"
     ]
    }
   ],
   "source": [
    "# Slope\n",
    "kf = KFold(n_splits=5,random_state=0)\n",
    "model_Slope_tune = SlopeOne()\n",
    "precision_Slope = []\n",
    "recall_Slope = []\n",
    "i = 1\n",
    "for trainset, testset in kf.split(data_set):\n",
    "    model_Slope_tune.fit(trainset)\n",
    "    predictions = model_Slope_tune.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=1.5)\n",
    "    p = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    r = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    \n",
    "    precision_Slope.append(p)\n",
    "    recall_Slope.append(r)\n",
    "    \n",
    "    # Precision and recall can then be averaged over all users\n",
    "    print('iter {} precisions:'.format(i),p)\n",
    "    print('iter {} recalls:'.format(i),r)\n",
    "    i += 1\n",
    "print('Mean Precision Score is ', np.mean(precision_Slope))\n",
    "print('std Precision Score is ', np.std(precision_Slope))\n",
    "print('Mean recall Score is ', np.mean(recall_Slope))\n",
    "print('std recall Score is ', np.std(recall_Slope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "iter 1 precisions: 0.929\n",
      "iter 1 recalls: 0.19042942839324412\n",
      "Estimating biases using als...\n",
      "iter 2 precisions: 0.918\n",
      "iter 2 recalls: 0.18465017662076474\n",
      "Estimating biases using als...\n",
      "iter 3 precisions: 0.921\n",
      "iter 3 recalls: 0.19781277056277055\n",
      "Estimating biases using als...\n",
      "iter 4 precisions: 0.944\n",
      "iter 4 recalls: 0.19775796536796533\n",
      "Estimating biases using als...\n",
      "iter 5 precisions: 0.938\n",
      "iter 5 recalls: 0.20115258352758347\n",
      "Mean Precision Score is  0.9299999999999999\n",
      "std Precision Score is  0.00985900603509295\n",
      "Mean recall Score is  0.19436058489446564\n",
      "std recall Score is  0.005988940568773352\n"
     ]
    }
   ],
   "source": [
    "# Baselineonly\n",
    "kf = KFold(n_splits=5,random_state=0)\n",
    "model_Baselineonly_tune = BaselineOnly()\n",
    "precision_Baselineonly = []\n",
    "recall_Baselineonly = []\n",
    "i = 1\n",
    "for trainset, testset in kf.split(data_set):\n",
    "    model_Baselineonly_tune.fit(trainset)\n",
    "    predictions = model_Baselineonly_tune.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=1.5)\n",
    "    p = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    r = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    \n",
    "    precision_Baselineonly.append(p)\n",
    "    recall_Baselineonly.append(r)\n",
    "    \n",
    "    # Precision and recall can then be averaged over all users\n",
    "    print('iter {} precisions:'.format(i),p)\n",
    "    print('iter {} recalls:'.format(i),r)\n",
    "    i += 1\n",
    "print('Mean Precision Score is ', np.mean(precision_Baselineonly))\n",
    "print('std Precision Score is ', np.std(precision_Baselineonly))\n",
    "print('Mean recall Score is ', np.mean(recall_Baselineonly))\n",
    "print('std recall Score is ', np.std(recall_Baselineonly))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
